<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>AAU Robot Dashboard</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <style>
    /* Overall Grid: 2 rows, 2 columns */
    #dashboard {
      display: grid;
      grid-template-rows: 50% 50%;
      grid-template-columns: 50% 50%;
      width: 100vw;
      height: 100vh;
      min-width: 1920px;
      min-height: 1080px;
      box-sizing: border-box;
      overflow: hidden;
    }
    .panel {
      border: 1px solid #444;
      background: #2a2a2a;
      position: relative;
      display: flex;
      flex-direction: column;
      padding: 8px;
      box-sizing: border-box;
    }
    .panel-title {
      position: absolute;
      top: 8px;
      left: 8px;
      font-weight: bold;
      color: #fff;
      z-index: 2;
    }
    /* For video/image in each window */
    .media-container {
      width: 100%;
      height: 100%;
      display: flex;
      align-items: center;
      justify-content: center;
      overflow: hidden;
      position: relative;
    }
    /* Ensure video/image fills the container width and scales */
    .media-content {
      width: 100%; /* Fill the full width of the container */
      height: 100%; /* Fill the full height of the container */
      object-fit: contain; /* Maintain aspect ratio while fitting within container */
      display: block;
    }
    #llmConsole {
      font-size: 2em;          /* twice the original size */
      line-height: 1.4;
      white-space: pre-wrap;   /* keep spaces & wrap long lines */
      word-break: break-word;
      color: #4af;             /* Blue for LLM Reasoning */
    }
    .console-area {
      background: #111;
      border: 1px solid #4af;
      font-family: monospace;
      padding: 4px;
      overflow-y: auto;
      flex: 1;
    }
    .neon-btn {
      background-color: #222;
      color: #4af;
      border: 1px solid #4af;
      transition: all 0.2s ease-in-out;
    }
    .neon-btn:hover {
      background-color: #4af;
      color: #111;
      box-shadow: 0 0 8px #4af;
    }
    select {
      background-color: #2a2a2a;
      color: #4af;
      border: 1px solid #4af;
      padding: 4px;
    }
    /* Chat messages font size matching LLM Reasoning */
    #chatMessages {
      font-size: 2em;          /* Match LLM Reasoning font size */
      line-height: 1.4;
      overflow-y: auto;
      background: #111;
      border: 1px solid #666;
      padding: 4px;
      margin-top: 8px;
    }
    /* Differentiate User and Max colors in Chat */
    #chatMessages div {
      color: #ffffff; /* Default white for the message content */
    }
    #chatMessages div strong {
      color: #ffffff; /* White for the sender name if it's the user */
    }
    #chatMessages div strong:first-child {
      color: #90ee90; /* Green for Max sender name */
    }
    #chatMessages div strong:first-child + * {
      color: #90ee90; /* Green for Max message content */
    }
  </style>
</head>
<body class="bg-gray-900 text-green-300">

<div id="dashboard">
  <!-- Row1, Col1: Camera Outputs (Segmentation and Depth side by side) -->
  <div class="panel" style="grid-row:1; grid-column:1; display:flex; flex-direction:row; padding:0;">
    <!-- Segmentation Output -->
    <div id="segContainer" class="media-container" style="flex:1; border-right:1px solid #333;">
      <div class="panel-title">Segmentation</div>
      <video id="segVideo" class="media-content" autoplay muted playsinline></video>
      <img id="segImg" class="media-content" src="https://via.placeholder.com/320x180?text=Seg" alt="SegOutput" style="display:none;">
    </div>
    <!-- Depth Output -->
    <div id="depthContainer" class="media-container" style="flex:1;">
      <div class="panel-title">Depth</div>
      <img id="depthImg" class="media-content" src="https://via.placeholder.com/320x180?text=Depth" alt="DepthOutput">
      <select id="depthMode" style="position:absolute; top:8px; right:8px; z-index:5;"></select>
    </div>
  </div>

  <!-- Row1, Col2: Robot Control -->
  <div class="panel" style="grid-row:1; grid-column:2; justify-content:center; align-items:center;">
    <div class="panel-title">Robot Control</div>
    <div style="margin-top:2rem; display:flex; gap:1rem;">
      <button class="neon-btn px-3 py-1" onclick="sendChatStream('move forward')">Forward</button>
      <button class="neon-btn px-3 py-1" onclick="sendChatStream('2 to the left')">Left x2</button>
      <button class="neon-btn px-3 py-1" onclick="sendChatStream('turn right')">Right</button>
    </div>
  </div>

  <!-- Row2, Col1: Chat -->
  <div class="panel" style="grid-row:2; grid-column:1;">
    <div class="panel-title">Chat</div>
    <!-- Welcome/Instructions Area (top 20%) -->
    <div style="height:20%; margin-top:30px; background:#0a0a0a; border:1px solid #4af; padding:8px; border-radius:4px; overflow-y:auto;">
      <div style="color:#4af; font-weight:bold; margin-bottom:4px;">ü§ñ AAU Robot Assistant</div>
      <div style="font-size:0.9em; line-height:1.3; color:#ccc;">
        <strong>Welcome!</strong> I can help you with:<br>
        ‚Ä¢ <strong>Pick objects:</strong> "Pick the red cup on the left"<br>
        ‚Ä¢ <strong>Place objects:</strong> "Place it in the dishwasher"<br>
        ‚Ä¢ <strong>Multi-step:</strong> "Pick the cup and place it on the table"<br>
        ‚Ä¢ <strong>Chat & ask questions</strong> about what I can see<br>
        <em style="color:#4af;">üí° Tip: Be specific about objects and locations!</em>
      </div>
    </div>
    <!-- Chat Messages Area (remaining 80%) -->
    <div id="chatMessages" style="flex:1; height:calc(80% - 40px);"></div>
    <div style="margin-top:8px; display:flex;">
      <input type="text" id="chatInput" class="bg-gray-800 text-green-300 border border-green-500 px-2 py-1 flex-1" placeholder="Type command...">
      <button id="chatSendBtn" class="neon-btn px-3 py-1" style="margin-left:8px;">Send</button>
    </div>
  </div>

  <!-- Row2, Col2: LLM Reasoning -->
  <div class="panel" style="grid-row:2; grid-column:2; display:flex; flex-direction:column;">
    <div class="panel-title">LLM Reasoning</div>
    <div id="llmConsole" class="console-area" style="margin-top:30px;"></div>
  </div>
</div>

<script>
  /****************************************************
   * ELEMENT REFS
   ****************************************************/
  const segVideo     = document.getElementById("segVideo");
  const segImg       = document.getElementById("segImg");
  const segContainer = document.getElementById("segContainer");
  const depthMode    = document.getElementById("depthMode");
  const depthImg     = document.getElementById("depthImg");
  const chatMessages = document.getElementById("chatMessages");
  const chatInput    = document.getElementById("chatInput");
  const chatSendBtn  = document.getElementById("chatSendBtn");
  const llmConsole   = document.getElementById("llmConsole");

  /****************************************************
   * STATE
   ****************************************************/
  let segFrozen          = false;
  let isSegmenting       = false;
  let realsenseSegTimer  = null;
  let depthTimer         = null;
  let realsenseAvailable = false;

  /****************************************************
   * PAGE LOAD
   ****************************************************/
  window.addEventListener("DOMContentLoaded", async () => {
    // Fetch camera info to check RealSense availability
    try {
      const res = await fetch("/camera_info");
      const info = await res.json();
      realsenseAvailable = info.realsense_available;
      console.log("RealSense available:", realsenseAvailable);
    } catch (e) {
      realsenseAvailable = false;
      console.error("Error checking camera info:", e);
      addChatMessage("Max", "Error checking RealSense availability. Functionality may be limited.");
    }

    updateDepthDropdown();

    // Automatically start RealSense for segmentation if available
    if (realsenseAvailable) {
      startRealSenseSeg();
      // Start depth processing with default option
      depthMode.value = "realsense_rgb_anything";
      depthTimer = setInterval(() => processDepth(depthMode.value), 500);
    } else {
      addChatMessage("Max", "RealSense not detected. Segmentation and Depth will be inactive.");
    }
  });

  /****************************************************
   * SEGMENTATION - RealSense Only
   ****************************************************/
  function startRealSenseSeg() {
    segVideo.style.display = "none";
    segImg.style.display = "block";
    realsenseSegTimer = setInterval(fetchRealsenseSeg, 250);
    console.log("Starting RealSense for segmentation.");
  }

  async function fetchRealsenseSeg() {
    try {
      const resp = await fetch("/process_realsense_seg", { method: "POST" });
      if (!resp.ok) throw new Error("Failed to fetch RealSense frame");
      const d = await resp.json();
      if (d.frame) segImg.src = "data:image/jpeg;base64," + d.frame;
    } catch (e) {
      console.error("RealSense fetch error:", e);
    }
  }

  // Freeze the Seg window ‚Äî no more frames will arrive until we unfreeze
  function freezeSegWindow(base64Frame) {
      segFrozen = true;
      isSegmenting = false; // Ensure it's not marked as segmenting to allow future clicks
      if (realsenseSegTimer) {
          clearInterval(realsenseSegTimer);
          realsenseSegTimer = null;
          console.log("Cleared RealSense timer to prevent frame updates. Timer ID: null");
      }

      // Swap to frozen JPEG
      segImg.src = "data:image/jpeg;base64," + base64Frame;
      segVideo.style.display = "none";
      segImg.style.display = "block";
      console.log("Segmentation window frozen with captured frame. State: segFrozen=" + segFrozen + ", isSegmenting=" + isSegmenting + ", Timer: " + (realsenseSegTimer ? "Active" : "Cleared"));
  }

  // Unfreeze & resume RealSense feed
  function unfreezeSegWindow() {
      segFrozen = false;
      fetch("/reset_seg", { method: "POST" }).catch(e => console.error("Reset seg error:", e));

      if (realsenseAvailable && !realsenseSegTimer) {
          realsenseSegTimer = setInterval(fetchRealsenseSeg, 250);
          console.log("Started RealSense timer for frame updates. Timer ID: " + realsenseSegTimer);
      }
      console.log("Segmentation window unfrozen. State: segFrozen=" + segFrozen + ", isSegmenting=" + isSegmenting + ", Timer: " + (realsenseSegTimer ? "Active" : "Not Started"));
  }

segContainer.addEventListener("click", async ev => {
    if (!realsenseAvailable) return;

    // FIRST CLICK: freeze and segment
    if (!segFrozen) {
        try {
            isSegmenting = true;
            console.log("First click: Capturing frame for segmentation. State before: segFrozen=" + segFrozen + ", isSegmenting=" + isSegmenting);
            const frameB64 = await captureSegFrame();
            freezeSegWindow(frameB64);

            // Get the image element and its bounding rectangle in the browser
            const imgElement = segImg.style.display !== "none" ? segImg : segVideo;
            const rr = imgElement.getBoundingClientRect();

            // Get the natural dimensions of the image (original size)
            const naturalWidth = imgElement.naturalWidth || imgElement.videoWidth || 640; // Fallback to expected width if unknown
            const naturalHeight = imgElement.naturalHeight || imgElement.videoHeight || 480; // Fallback to expected height if unknown

            // Compute the displayed dimensions and aspect ratio
            const displayedWidth = rr.width;
            const displayedHeight = rr.height;
            const aspectRatio = naturalWidth / naturalHeight;

            // Calculate the actual content area within the container (due to object-fit: contain)
            let contentWidth, contentHeight, offsetX, offsetY;
            if (displayedWidth / displayedHeight > aspectRatio) {
                // Image is constrained by height, black bars on sides
                contentHeight = displayedHeight;
                contentWidth = displayedHeight * aspectRatio;
                offsetX = (displayedWidth - contentWidth) / 2;
                offsetY = 0;
            } else {
                // Image is constrained by width, black bars on top/bottom
                contentWidth = displayedWidth;
                contentHeight = displayedWidth / aspectRatio;
                offsetY = (displayedHeight - contentHeight) / 2;
                offsetX = 0;
            }

            // Compute click position relative to the content area
            const clickX = ev.clientX - rr.left - offsetX;
            const clickY = ev.clientY - rr.top - offsetY;

            // Normalize click coordinates to the natural image dimensions
            const nx = (clickX / contentWidth) * naturalWidth;
            const ny = (clickY / contentHeight) * naturalHeight;

            // Ensure coordinates are within bounds
            const clampedNx = Math.max(0, Math.min(naturalWidth, nx)) / naturalWidth;
            const clampedNy = Math.max(0, Math.min(naturalHeight, ny)) / naturalHeight;

            console.log(`Click at normalized coords: (${clampedNx.toFixed(3)}, ${clampedNy.toFixed(3)}) based on natural size ${naturalWidth}x${naturalHeight}`);

            const resp = await fetch("/process_seg", {
                method: "POST",
                headers: { "Content-Type": "application/json" },
                body: JSON.stringify({ frame: frameB64, clicked_x: clampedNx, clicked_y: clampedNy })
            });
            if (resp.ok) {
                const dd = await resp.json();
                if (dd.object_info) {
                    addChatMessage(
                        "Max",
                        `Center: ${dd.object_info.center_xyz_m.map(v => v.toFixed(3)).join(', ')} m; ` +
                        `distance ${dd.object_info.distance_m.toFixed(3)} m; ` +
                        `W√óH ${(dd.object_info.width_m * 100).toFixed(1)}√ó${(dd.object_info.height_m * 100).toFixed(1)} cm`
                    );
                }
                // Update overlay on frozen image
                segImg.src = "data:image/jpeg;base64," + dd.frame;
                console.log("Updated image with segmentation results. State after: segFrozen=" + segFrozen + ", isSegmenting=" + isSegmenting);
            }
        } catch (e) {
            console.error("Seg error:", e);
        } finally {
            isSegmenting = false;
            console.log("Segmentation complete. Final state: segFrozen=" + segFrozen + ", isSegmenting=" + isSegmenting);
        }
    }
    // SECOND CLICK: unfreeze
    else {
        unfreezeSegWindow();
    }
});

  /****************************************************
   * DEPTH
   ****************************************************/
  function updateDepthDropdown() {
    if (realsenseAvailable) {
      depthMode.innerHTML = `
        <option value="realsense_rgb_anything">RealSense RGB + Depth Anything</option>
        <option value="realsense_depth">RealSense Depth</option>
      `;
    } else {
      depthMode.innerHTML = `
        <option value="unavailable">Unavailable</option>
      `;
      depthMode.disabled = true;
      addChatMessage("Max", "RealSense not available. Depth options are disabled.");
    }
  }

  depthMode.addEventListener("change", () => {
    clearInterval(depthTimer);
    depthImg.src = "https://via.placeholder.com/320x180?text=Depth";
    const v = depthMode.value;
    if (realsenseAvailable && v !== "unavailable") {
      depthTimer = setInterval(() => processDepth(v), 500);
    }
  });

  async function processDepth(mode) {
    try {
      const r = await fetch("/process_depth", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ camera_mode: mode, local_idx: 0, frame: "" })
      });
      const d = await r.json();
      if (d.frame) depthImg.src = "data:image/jpeg;base64," + d.frame;
    } catch (e) {
      console.error("Depth processing error:", e);
    }
  }

  /****************************************************
   * FRAME CAPTURE UTILS
   ****************************************************/
  function captureSegFrame() {
    return new Promise((res, rej) => {
      if (realsenseAvailable) {
        const p = segImg.src.split(",");
        p[1] ? res(p[1]) : rej("No RealSense frame");
      } else {
        rej("RealSense not available");
      }
    });
  }

  /****************************************************
   * CHAT
   ****************************************************/
  function addChatMessage(sender, msg) {
    if (chatMessages.children.length > 2000) chatMessages.removeChild(chatMessages.firstChild);
    const dv = document.createElement("div");
    dv.innerHTML = `<strong>${sender}:</strong> ${msg}`;
    chatMessages.appendChild(dv);
    chatMessages.scrollTop = chatMessages.scrollHeight;
  }

  async function sendChatStream(customText) {
      const userText = (customText || chatInput.value).trim();
      if (!userText) return;

      chatInput.value = "";
      addChatMessage("You", userText);

      // Clear reasoning window
      llmConsole.innerHTML = "";

      // Unfreeze segmentation window and reset state to ensure fresh frames
      unfreezeSegWindow();

      try {
          console.log("üîç Attempting streaming request...");
          const success = await tryStreamingChat(userText);

          if (!success) {
              console.log("üîÑ Streaming failed, trying non-streaming fallback...");
              await tryFallbackChat(userText);
          }
      } catch (error) {
          console.error("‚ùå Chat error:", error);
          addChatMessage("Max", `Error: ${error.message}. Please try again.`);
      }
  }

  async function tryStreamingChat(userText) {
      try {
          const resp = await fetch("/chat-stream", {
              method: "POST",
              headers: { "Content-Type": "application/json" },
              body: JSON.stringify({ text: userText })
          });

          if (!resp.ok) {
              console.log(`‚ùå Streaming response not ok: ${resp.status}`);
              return false;
          }

          const reader = resp.body.getReader();
          const decoder = new TextDecoder();
          let reasoning = "";
          let answer = "";
          let actionBuffer = "";

          while (true) {
              const { done, value } = await reader.read();
              if (done) break;

              const chunk = decoder.decode(value, { stream: true });
              const lines = chunk.split('\n');

              for (const line of lines) {
                  if (!line.trim()) continue;

                  if (line.startsWith("data: ")) {
                      let content = line.slice(6).trim();

                      if (content === "[DONE]") break;

                      // Handle thinking and response content
                      if (content.startsWith("thinking:")) {
                          const thinkingToken = content.slice(9);
                          // Add space if needed before appending token
                          if (reasoning && thinkingToken && needsSpace(reasoning, thinkingToken)) {
                              reasoning += " " + thinkingToken;
                          } else {
                              reasoning += thinkingToken;
                          }
                          llmConsole.innerHTML = reasoning;
                          llmConsole.scrollTop = llmConsole.scrollHeight;
                      } else if (content.startsWith("response:")) {
                          const responseToken = content.slice(9);
                          // Add space if needed before appending token
                          if (answer && responseToken && needsSpace(answer, responseToken)) {
                              answer += " " + responseToken;
                          } else {
                              answer += responseToken;
                          }
                          actionBuffer += responseToken;
                      } else {
                          // Add space if needed before appending token
                          if (answer && content && needsSpace(answer, content)) {
                              answer += " " + content;
                          } else {
                              answer += content;
                          }
                          actionBuffer += content;
                      }

                      // Check for [ACTION] in the accumulated buffer
                      if (actionBuffer.includes("[ACTION]")) {
                          console.log("‚úÖ [ACTION] block detected in streaming!");
                          const actionResult = extractAndProcessAction(actionBuffer);
                          if (actionResult.processed) {
                              actionBuffer = actionResult.remainingBuffer;
                              return true; // Exit early since action is being handled
                          }
                      }
                  }
              }
          }

          // After streaming, if no action was processed, show the response
          if (answer.trim() && !answer.includes("[ACTION]")) {
              console.log("‚úÖ No action detected, showing regular chat response.");
              addChatMessage("Max", answer.trim());
              return true;
          }

          // Final attempt to process action if present
          if (actionBuffer.includes("[ACTION]")) {
              console.log("‚úÖ [ACTION] detected at stream end, final processing attempt.");
              const actionResult = extractAndProcessAction(actionBuffer);
              if (actionResult.processed) {
                  return true;
              }
          }

          console.log("‚ùå No valid response or action processed.");
          return false;
      } catch (error) {
          console.error("‚ùå Streaming error:", error);
          return false;
      }
  }

  // Helper function to determine if a space is needed between two text fragments
  function needsSpace(existingText, newToken) {
      // If either string is empty, no space is needed
      if (!existingText || !newToken) return false;

      // Get the last character of existing text and first character of new token
      const lastChar = existingText.slice(-1);
      const firstChar = newToken[0];

      // If the last character is a space or punctuation, no additional space is needed
      if (/\s|[.,!?;]/.test(lastChar)) return false;

      // If the first character is a space or punctuation, no additional space is needed
      if (/\s|[.,!?;]/.test(firstChar)) return false;

      // If both characters are alphanumeric, a space is likely needed
      if (/[a-zA-Z0-9]/.test(lastChar) && /[a-zA-Z0-9]/.test(firstChar)) return true;

      // Default: no space needed (e.g., connecting symbols or mixed cases)
      return false;
  }

  function extractAndProcessAction(buffer) {
    const actionIndex = buffer.indexOf("[ACTION]");
    if (actionIndex === -1) {
      return { processed: false, remainingBuffer: buffer };
    }

    // Extract content after [ACTION]
    const actionContent = buffer.slice(actionIndex).trim();
    console.log("üîç Extracted [ACTION] content:", actionContent);

    // Split into lines for parsing
    const lines = actionContent.split('\n').filter(line => line.trim());
    console.log("üîç Lines in [ACTION] block:", lines);

    // If fewer than 2 lines, wait for more content
    if (lines.length < 2) {
      console.log("üîç Partial [ACTION] block, waiting for more content.");
      return { processed: false, remainingBuffer: buffer };
    }

    // Look for RoboPoint Request and Action Request with flexible matching
    let roboPointLine = null;
    let actionLine = null;

    for (const line of lines) {
      if (!roboPointLine && line.toLowerCase().includes("robopoint") && line.toLowerCase().includes("request")) {
        roboPointLine = line;
        console.log("‚úÖ Found RoboPoint line (flexible match):", line);
      } else if (!actionLine && line.toLowerCase().includes("action") && line.toLowerCase().includes("request")) {
        actionLine = line;
        console.log("‚úÖ Found Action line (flexible match):", line);
      }
    }

    // If not found, check the entire content for keywords (less strict)
    if (!roboPointLine) {
      for (const line of lines) {
        if (line.toLowerCase().includes("robopoint") || line.toLowerCase().includes("object") || line.toLowerCase().includes("find")) {
          roboPointLine = line;
          console.log("‚úÖ Found RoboPoint line (keyword match):", line);
          break;
        }
      }
    }

    if (!actionLine) {
      for (const line of lines) {
        if (line.toLowerCase().includes("action") || line.toLowerCase().includes("pick") || line.toLowerCase().includes("place")) {
          actionLine = line;
          console.log("‚úÖ Found Action line (keyword match):", line);
          break;
        }
      }
    }

    // If still not found, report error but log full content for debugging
    if (!roboPointLine) {
      console.log("‚ùå Could not find RoboPoint Request line in:", lines);
      addChatMessage("Max", `Error: Missing 'RoboPoint Request:' line. Full response logged for debugging.`);
      addChatMessage("Max", `Debug content: ${actionContent.length > 200 ? actionContent.substring(0, 200) + '...' : actionContent}`);
      return { processed: false, remainingBuffer: buffer };
    }

    if (!actionLine) {
      console.log("‚ùå Could not find Action Request line in:", lines);
      addChatMessage("Max", `Error: Missing 'Action Request:' line. Full response logged for debugging.`);
      addChatMessage("Max", `Debug content: ${actionContent.length > 200 ? actionContent.substring(0, 200) + '...' : actionContent}`);
      return { processed: false, remainingBuffer: buffer };
    }

    // Process the action
    console.log("‚úÖ Complete [ACTION] block found, processing...");
    addChatMessage("Max", "ü§ñ Processing action request... Searching for objects.");
    executeMultiStepActions(actionContent);

    const remainingBuffer = buffer.slice(actionIndex + actionContent.length).trim();
    return { processed: true, remainingBuffer };
  }

  async function tryFallbackChat(userText) {
    try {
      addChatMessage("Max", "Processing your request...");
      const resp = await fetch("/chat", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ text: userText })
      });

      if (!resp.ok) {
        throw new Error(`Server error: ${resp.status}`);
      }

      const data = await resp.json();
      console.log("üîç Fallback response:", data);

      const response = data.reply || data.answer || "";
      if (response) {
        if (response.includes("[ACTION]")) {
          console.log("‚úÖ [ACTION] detected in fallback response, processing...");
          addChatMessage("Max", "ü§ñ Processing action request... Searching for objects.");
          await executeMultiStepActions(response);
        } else {
          console.log("‚úÖ No action in fallback, showing regular response.");
          addChatMessage("Max", response);
        }
      } else {
        addChatMessage("Max", "No response received from fallback.");
      }
    } catch (error) {
      console.error("‚ùå Fallback error:", error);
      addChatMessage("Max", `Fallback error: ${error.message}`);
    }
  }

async function executeMultiStepActions(actionBlock) {
    console.log("üîç DEBUG: Raw action block:", actionBlock);

    try {
        // Extract [ACTION] block content
        const actionMatch = actionBlock.match(/\[ACTION\]\s*([\s\S]*?)(?:\n\n|$)/i);
        if (!actionMatch) {
            throw new Error("Could not find [ACTION] block in response");
        }

        const content = actionMatch[1].trim();
        console.log("üîç DEBUG: Action content:", content);

        // Split into lines, handle single line with both requests
        let lines = content.split('\n').map(line => line.trim()).filter(line => line);
        if (lines.length === 1 && lines[0].includes("Action Request:")) {
            const idx = lines[0].indexOf("Action Request:");
            lines = [
                lines[0].slice(0, idx).trim(),
                lines[0].slice(idx).trim()
            ];
        }
        console.log("üîç DEBUG: All lines:", lines);

        // Find the required lines
        let roboPointLine = null;
        let actionLine = null;

        for (const line of lines) {
            if (line.match(/^\s*RoboPoint\s+Request\s*:/i)) {
                roboPointLine = line;
                console.log("‚úÖ Found RoboPoint line:", line);
            } else if (line.match(/^\s*Action\s+Request\s*:/i)) {
                actionLine = line;
                console.log("‚úÖ Found Action line:", line);
            }
        }

        // Detailed error reporting
        if (!roboPointLine) {
            console.log("‚ùå Available lines:", lines);
            addChatMessage("Max", `Error: Missing 'RoboPoint Request:' line.`);
            return;
        }

        if (!actionLine) {
            console.log("‚ùå Available lines:", lines);
            addChatMessage("Max", `Error: Missing 'Action Request:' line.`);
            return;
        }

        // Extract content after colons
        const roboPointContent = roboPointLine.split(':', 2)[1];
        const actionContent = actionLine.split(':', 2)[1];

        if (!roboPointContent || !actionContent) {
            addChatMessage("Max", "Error: Could not extract content from request/action lines");
            return;
        }

        // Parse the semicolon-separated values
        const objects = roboPointContent.split(';').map(s => s.trim()).filter(s => s);
        const actions = actionContent.split(';').map(s => s.trim()).filter(s => s);

        console.log("üîç DEBUG: Parsed objects:", objects);
        console.log("üîç DEBUG: Parsed actions:", actions);

        if (objects.length !== actions.length) {
            addChatMessage("Max", `Error: Mismatch between objects (${objects.length}) and actions (${actions.length}).`);
            return;
        }

        if (objects.length === 0) {
            addChatMessage("Max", "Error: No valid commands found in the action block");
            return;
        }

        // Success - start processing
        addChatMessage("Max", `‚úÖ Found ${objects.length} command(s). Starting execution...`);

        // Unfreeze segmentation window to ensure fresh frames for RoboPoint actions
        unfreezeSegWindow();

        // Wait briefly to ensure a fresh frame is fetched
        await new Promise(resolve => setTimeout(resolve, 300));

        // Capture frame
        let frameB64 = "";
        try {
            frameB64 = await captureSegFrame();
            freezeSegWindow(frameB64);
        } catch (e) {
            console.warn("No seg frame:", e);
            addChatMessage("Max", "Warning: Could not capture frame. Continuing anyway...");
        }

        // Execute each command
        for (let i = 0; i < objects.length; i++) {
            const object = objects[i];
            const action = actions[i];

            addChatMessage("Max", `üîÑ Step ${i+1}: Finding "${object}"...`);

            try {
                const result = await executeRoboPointCommand(object, action, frameB64);

                if (result.seg_frame) {
                    segImg.src = "data:image/jpeg;base64," + result.seg_frame;
                    console.log("Updated image with RoboPoint results. State after: segFrozen=" + segFrozen + ", isSegmenting=" + isSegmenting);
                }

                // Show location for both pick and place
                if (result.object_info && result.object_info.center_xyz_m) {
                    const info = result.object_info;
                    addChatMessage("Max", 
                        `‚úÖ Step ${i+1}: Successfully found "${object}"! Location: ${info.center_xyz_m.map(v=>v.toFixed(3)).join(', ')} m, Distance: ${info.distance_m.toFixed(3)} m, Size: ${(info.width_m*100).toFixed(1)}√ó${(info.height_m*100).toFixed(1)} cm`
                    );
                } else {
                    addChatMessage("Max", `‚úÖ Step ${i+1}: Successfully found "${object}"`);
                }

                // Pause between steps
                if (i < objects.length - 1) {
                    await new Promise(resolve => setTimeout(resolve, 800));
                }
            } catch (error) {
                console.error(`‚ùå Step ${i+1} failed:`, error);
                addChatMessage("Max", `‚ùå Step ${i+1} Failed: ${error.message}`);
                break;
            }
        }

        addChatMessage("Max", `üéâ Completed ${objects.length} action(s)!`);
        // Do NOT unfreeze here; keep the mask and results visible until user interaction
        console.log("Keeping segmentation window frozen to show results. Click or send a new message to unfreeze. State: segFrozen=" + segFrozen + ", isSegmenting=" + isSegmenting + ", Timer: " + (realsenseSegTimer ? "Active" : "Cleared"));
    } catch (error) {
        console.error("‚ùå Action parsing error:", error);
        addChatMessage("Max", `Action parsing error: ${error.message}`);
        // Unfreeze in case of error to prevent getting stuck
        unfreezeSegWindow();
    }
}
  
  async function executeRoboPointCommand(objectDescription, action, frameB64) {
    const singleActionBlock = `[ACTION]\nRoboPoint Request: ${objectDescription}\nAction Request: ${action}`;
    
    console.log("üì§ Sending to RoboPoint:", singleActionBlock);
    
    const resp = await fetch("/exec_action", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({
        action_block: singleActionBlock,
        seg_frame: frameB64
      })
    });

    if (!resp.ok) {
      const errorText = await resp.text();
      throw new Error(`Server error ${resp.status}: ${errorText}`);
    }

    const result = await resp.json();
    console.log("üì• RoboPoint result:", result);
    
    if (result.error) {
      throw new Error(result.error);
    }
    
    return result;
  }

  /****************************************************
   * EVENT LISTENERS FOR CHAT
   ****************************************************/
  chatSendBtn.addEventListener("click", () => sendChatStream());
  chatInput.addEventListener("keyup", e => { if (e.key === "Enter") sendChatStream(); });
</script>